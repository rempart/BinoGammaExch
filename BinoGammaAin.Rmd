---
title: "Essais  de la mise en oeuvre du Bayesian Forecasting System sur un modèle Bernoulli-Gamma échangeable d'ensemble de membres de pluies"
author: "Eric Parent"
date: "14 janvier partie 1 : Prévision binaire sur Vouglans"
fontsize: 9pt
includes:
      in_header: stylepandoc.tex
output: 
  pdf_document:
    number_sections: true
    latex_engine: xelatex
    keep_tex: true
---

# Avertissement

Ce document reprends une de mes nombreuses discussions avec Jacques Bernier, ainsi que de nos échanges épistolaires de notes, d'études et de
contre-études depuis que je me suis engagé sur les prévisions
d'ensemble. 

* J'explore le modèle Binomial-Gamma sur les pluies de Vouglans et le modèle Binomial-Gamma échangeable pour les membres de l'ensemble du CEP. 

* Pour prévoir le caractère sec vs humide, j'utilise les concepts développés par Roman
Krzysztofowicz depuis de nombreuses années dans le domaine de la prévision, et notamment la prévision d'ensemble : la modélisation de la loi marginale de l'ensemble $X$  est utilisée comme un code boite noire pour créer une variable $Z$ que l'on cherche ensuite à relier à l'observation $Y$. 

* Je m'appuie sur l'outil d'inférence bayésienne *STAN* pour réaliser, par Hamilton Monte Carlo, l'estimation préquentielle de cette prédictive marginale. 

* On travaille sur les données de Vouglans, divisée en deux morceaux, l'un pour le calage, l'autre pour la validation. 

* Les premiers résultats semblent positifs en terme de prévision du caractère binaire: sec ou humide. On abordera ultérieurement le problème de la prévision de la quantité de pluie (grâce à la NQT), quand pluie il y a.
 
```{r setup, results = 'hide', message = FALSE, warning = FALSE}
# Ne pas oublier de positionner Rstudio sur le chemin du répertoire de travail
rm(list=ls())
library(rstan)
rstan_options(auto_write = TRUE)
knitr::opts_chunk$set(echo = TRUE)
options(digits=3,width=80)
library(tidyverse)
library(ggplot2)
seuil=0.1 #mn
printemps = (31+28+15):(31+28+31+30+31+15)
saison = printemps
horizon = 4 #jours
K=50 #membres
datecharniere="2011-01-01"
base<-function(t){
  cbind(0*t+1,sin(2*pi*t/365),cos(2*pi*t/365),
        sin(2*pi*2*t/365),cos(2*pi*2*t/365),
        sin(2*pi*3*t/365),cos(2*pi*3*t/365))
}

```
J'ai choisi un seuil de `r seuil` mm, un horizon de `r horizon` jours et la période du printemps pour être en accord avec les essais récents de Jacques. Dans
ce document et les programmes associés, nous illustrons les idées en
travaillant avec les données de pluies journalières à la station de
Vouglans fournies par EDF \footnote{Les données d'HydroQuébec sont
également susceptibles d'un traitement de même nature.}. La période de calage comprend les données antérieures au `r datecharniere`, celle de validation les suivantes.

# Chargement des données et data cleaning

On charge d'abord les données climatologiques stockées
dans le fichier AINhist.Rdata. On supprime les jours additionnels provenant des années bissextiles, on ajoute une colonne calendaire et on crée un dataframe (tibble) *datahisto*.

On récupère ensuite les membres de l'ensemble CEP pour Vouglans de 2005 à 2008 à partir du fichier *AIN20052008.Rdata*, on y ajoute une variable calendaire, puis on réalise les mêmes opérations pour les années 2011 à 2015 à partir du fichier *AIN20112015.Rdata* (petit problème de dates incohérentes réglé) en ne gardant le même nombre d'horizons de prédiction que celui que 2005 à 2008 ainsi que les mêmes noms de colonnes.

Le dataframe des données nettoyées complètes s'appelle *datao*.
On en profite également pour faire un nettoyage de la mémoire de l'ordinateur afin de ne conserver que les quantités essentielles.

```{r datacleaning, results = 'hide', message = FALSE, warning = FALSE}
## ----ChargeVouglansHistorique
load("AINhist.Rdata")
bisextil=grep(pattern = '-02-29',x=t.hist)
data.histo<-tibble(Date=t.hist[-bisextil], y=y.hist[-bisextil], calendaire=rep(1:365,length(Date)/365))
## ----ChargeVouglans20052008
load("AIN20052008.Rdata") # cree data
nbech20052008=max(data$Echeance)
training20052008o=as.tibble(data)
bisextil=grep(pattern = '-02-29',x=training20052008o$Date)
l=1:dim(training20052008o)[1]
l=(-1+l)%/%nbech20052008
numjour=(l+(training20052008o$Echeance))
numjour[training20052008o$Date>"2008-12-31"]=numjour[training20052008o$Date>"2008-12-31"]-1
training20052008o$calendaire=((-1+(numjour))%%365)+1
tail(training20052008o)
## ----Charge200112015
load("AIN20112015.Rdata") # cree data
##TESTER Completude base
# data %>% group_by(Echeance) %>% summarize(n())
data$Date[1]->debut
nbech=max(unique(data$Echeance))
nbjours=dim(data)[1]/nbech
rythme=rep(1:nbech,nbjours)+rep(0:(nbjours-1),each=nbech)
DateCheck=debut+rythme-1
data %>% mutate(Check=(Date!=DateCheck)) %>% 
  group_by(Echeance) %>% summarize(n(),sum(Check)) 
#pour verifier que tout est OK
which(data$Date!=DateCheck)->pb
# A comparer data$Date[pb] et DateCheck[pb]
data$Date[pb]<-DateCheck[pb] 
validation20112015o=as.tibble(data)
bisextil=grep(pattern = '-02-29',x=validation20112015o$Date)
l=1:dim(validation20112015o)[1]
l=(-1+l)%/%nbech
numjour=(l+(validation20112015o$Echeance))
numjour[validation20112015o$Date>"2012-12-31"]=numjour[validation20112015o$Date>"2012-12-31"]-1
validation20112015o$calendaire=((-1+(numjour))%%365)+1
tail(validation20112015o)
tail(training20052008o)
head(validation20112015o)
## ----fairbasetotale
#####################
colnames(validation20112015o)=colnames(training20052008o)
validation20112015o %>% filter(Echeance<=nbech20052008) %>% 
  rbind(training20052008o,.) ->datao
#Nettoyage
memoire=c("seuil","horizon", "K", "printemps","base",
          "data.histo","datao","datecharniere",
          "saison")
LS=ls(); listeajeter=NULL
for (elementajeter in LS){if (!(elementajeter %in% memoire))
  listeajeter=c(listeajeter,elementajeter) }
rm(list=c(listeajeter,"listeajeter","elementajeter","LS"))
```


# Analyse marginale de l'ensemble $[X]$

La base de données *dtout* conserve les statistiques exhaustives $NX,SX,SLX$ du modèle Bino-Gamma des pluies pour l'échéance de prédiction et la période calendaire choisies.
```{r preparation, results = 'hide', message = FALSE, warning = FALSE}
is.nonzero<-function(x){ifelse(x>seuil,1,0)}
take.log<-function(x){ifelse(x>0,log(x),0)}
datao %>% 
  mutate(NX=rowSums(is.nonzero(select(.,starts_with("CEP")))),
         SX=rowSums(select(.,starts_with("CEP")))) %>% 
  mutate_at(vars(matches("CEP")), take.log) %>% 
  mutate(SLX=rowSums(select(.,starts_with("CEP"))))   %>% 
  select(-starts_with("CEP")) %>% 
  filter(Echeance==horizon) %>% 
  arrange(NX) %>% 
  filter(!is.na(NX),calendaire %in% saison)->dtout
```

## Apprentissage

La log-probabilité de l' ensemble à la date $t$ s'écrit:
$${L_t} = N{X_t}\log ({\pi _t}) + (K - N{X_t})\log (1 - {\pi _t}) - N{X_t}\log (\Gamma ({\gamma _t})) + {\gamma _t}N{X_t}\log {\alpha _t} + ({\gamma _t} - 1)SL{X_t}$$
On va utiliser STAN pour réaliser l'inférence de ce type de modèle avec pour effet aléatoire:

* la variable latente $\pi_t$ distribué comme une loi beta de paramètres $a$ et $b$

* la variable latente $\alpha_t$ distribué comme une loi gamma de paramètres $g$ et $c$

* la variable latente $\gamma_t$ est choisie distribué comme une loi de Dirac ( donc pas d'effet aléatoire on supprime cette variable latente, qui passe au statut de paramètre $\gamma$ )

et des lois uniformes vagues pour les paramètres $a,b,g,c,\gamma$ notés respectivement *a_NX*, *b_NX*, *g_alpha_SX*, *c_alpha_SX* et *gamma_SX* dans le programme informatique.

L'intérêt de STAN, outre l'efficacité de l'exploration Monte Carlo Hamiltonienne, est qu'on peut directement écrire la log probabilité dans le script grace à l'instruction *target +=* qui accumule dans la log probabilité du modèle à estimer  (voir fonction *ExchBinoGamma_lp* ci-après)

```{r modelstan, include = T}
model_string<-"
functions {
  // Function that returns the log pdf of the Exchangeable BinoGamma model 
 real ExchBinoGamma_lp( int Nx, real Sx, real SLx, 
 real alpha, real gam) {
 return((gam-1)*SLx -alpha*Sx+gam*Nx*log(alpha)-Nx*lgamma(gam));
 }
 }
data {
int<lower=0> K;         // size of the ensemble 50
int<lower=0> T;         // number of observations 
int NX[T];         // number of non zero members 
real SX[T];    // nonzero sum of members 
real SLX[T];    // nonzero sum of members 
}
parameters {
real<lower=0> a_NX;      // first coeff of beta 
real<lower=0> b_NX;      // second coeff of beta
real<lower=0,upper=1> pi[T];   // beta distributed effect by time
real<lower=0> gamma_SX;      // second coeff of gamma
real<lower=0> alpha_SX[T];      // first coeff of gamma
real<lower=0> g_alpha_SX;      // first coeff of gamma gamma
real<lower=0> c_alpha_SX;      // second coeff of gamma gamma
}

model {
target += binomial_lpmf(NX | K, pi); // log-likelihood
target += beta_lpdf(pi | a_NX, b_NX);       // random effect
target += gamma_lpdf(alpha_SX | g_alpha_SX, c_alpha_SX);       // random effect
target += uniform_lpdf(a_NX | 0, K); // prior
target += uniform_lpdf(b_NX | 0, K); // prior
target += exponential_lpdf(gamma_SX | 1); // prior
target += uniform_lpdf(g_alpha_SX | 0, 1000*K); // prior
target += uniform_lpdf(c_alpha_SX | 0, 1000*K); // prior
  for (t in 1:T){
target += ExchBinoGamma_lp(NX[t], SX[t], SLX[t], 
alpha_SX[t], gamma_SX);
}
}
"
```

On va créer successivement un fichier d'apprentissage
*d* pour la situation de pluie nulle puis pour celle de pluie positive. Sur chaque jeu, on ajuste une loi bino-gamma échangeable dont on stocke la loi a posteriori des paramètres dans le fichier  *fitsPrintemps.RData*. Je vais souvent noter dans la suite *d* pour la **datatable** de travail.

```{r fitstan, include=TRUE}
if(!file.exists("fitsPrintemps.RData")){
dtout %>% filter(Date<datecharniere, Obs<=seuil)->d
NX_dat <- list(K = 50, 
                    NX = d$NX,
                    T = length(d$NX),
                    SX = d$SX,
                    SLX = d$SLX
               )
fit0 <- stan(model_code=model_string, data = NX_dat)
dtout %>% filter(Date<datecharniere, Obs>seuil)->d
NX_dat <- list(K = 50, 
                    NX = d$NX,
                    T = length(d$NX),
                    SX = d$SX,
                    SLX = d$SLX
               )
fit1 <- stan(model_code=model_string, data = NX_dat)
save(fit0, fit1, file = "fitsPrintemps.RData")
}
load(file="fitsPrintemps.RData")
```
 
 Pour chaque situation (pluie nulle à la figure 1 ou positive à la figure 2), on constate que les paramètres de $\pi_t$ ($a$ et $b$) d'une part et de $\alpha_t$ d'autre part ($g$ et $c$) sont a posteriori très correlés, tandis que l'on observe pas de liaison entre les paramètres de $\pi_t$, ceux de $\alpha_t$, et le $\gamma$. En situation de pluie, on retrouve une valeur de $\gamma$ proche de $1$ donc un modèle d'occurrence de type *loi exponentielle* pour les quantités de pluie prévue (voir tableaux 1 et 2).
 
### Inférence sur la situation sèche
 
``` {r fig0, fig.cap="posterior des paramètres situation sèche"}
pairs(fit0, pars = c("a_NX", "b_NX","gamma_SX", "g_alpha_SX", "c_alpha_SX"))
```
```{r printtabO, results='asis', message = FALSE, warning = FALSE}
simu0<-rstan::extract(fit0, pars = c("a_NX", "b_NX","g_alpha_SX","c_alpha_SX","gamma_SX" ))
out0<-tibble(a=simu0$a_NX,b=simu0$b_NX,
            g=simu0$g_alpha_SX,
            c=simu0$c_alpha_SX,
            gamma=simu0$gamma_SX)

IC90fit0 = apply(out0,2,quantile,prob=c(.05,.5,.95))
knitr::kable( IC90fit0,caption = "Statistiques a posteriori des paramètres en situation sèche")
```
 
### Inférence sur la situation humide
 
```{r fig1, fig.cap="posterior des paramètres situation humide"}
pairs(fit1, pars = c("a_NX", "b_NX","gamma_SX", "g_alpha_SX", "c_alpha_SX"))
```

```{r printtab1, results='asis', message = FALSE, warning = FALSE}
simu1<-rstan::extract(fit1, pars = c("a_NX", "b_NX","g_alpha_SX","c_alpha_SX","gamma_SX" ))
out1<-tibble(a=simu1$a_NX,b=simu1$b_NX,
            g=simu1$g_alpha_SX,
            c=simu1$c_alpha_SX,
            gam=simu1$gamma_SX)

IC90fit1 = apply(out1,2,quantile,prob=c(.05,.5,.95))
knitr::kable( IC90fit1,caption = "Statistiques a posteriori des paramètres en situation humide")
```

### Inférence préquentielle
On modèlise la loi marginale de l'ensemble sous la forme d'un mélange des deux situations ($Z=1$ situation humide, $Z=0$ situation anticipée sèche) où chaque composante suit la *prédictive* de la Bino-Gamma échangeable inférée précédemment. Ce calcul va se faire sur toute la base (calage+validation) en prévision des opérations futures

```{r predictivecomposeche,results = 'hide', message = FALSE, warning = FALSE}
d<-dtout
LogExchBinoGamma<-function(Nx, Sx, SLx, p, alpha, gam) {
  res=(Nx*log(p)+(K-Nx)*log(1-p)+
         (gam-1)*SLx -alpha*Sx+
         gam*Nx*log(alpha)-Nx*lgamma(gam))
}
simu0$p<-rbeta(4000,simu0$a_NX,simu0$b_NX)
simu0$alpha<-rgamma(4000,simu0$g_alpha_SX,simu0$c_alpha_SX)
AjoutLogProb0<-function(i){
  test=LogExchBinoGamma(as.numeric(d[i,"NX"]), 
                        as.numeric(d[i,"SX"]),
                        as.numeric(d[i,"SLX"]),
                        simu0$p, simu0$alpha, simu0$gamma_SX) 
  LogProb=max(test,na.rm = T)+log(mean(exp(test-max(test,na.rm = T)),na.rm=T))
}
sapply(1:length(d$NX),AjoutLogProb0)->d$LogProb0
############
simu1$p<-rbeta(4000,simu1$a_NX,simu1$b_NX)
simu1$alpha<-rgamma(4000,simu1$g_alpha_SX,simu1$c_alpha_SX)
AjoutLogProb1<-function(i){
  test=LogExchBinoGamma(as.numeric(d[i,"NX"]), 
                        as.numeric(d[i,"SX"]),
                        as.numeric(d[i,"SLX"]),
                        simu1$p, simu1$alpha, simu1$gamma_SX) 
  LogProb=max(test,na.rm = T)+log(mean(exp(test-max(test,na.rm = T)),na.rm=T))
}
sapply(1:length(d$NX),AjoutLogProb1)->d$LogProb1
#############
dtout<-d
```
On calcule ensuite la proportion du mélange sur l'échantillon de calage:
```{r calculerho, results = 'hide', message = FALSE, warning = FALSE}
dtout %>% filter(Date<datecharniere)->d
ro<-0.5
tol<-0.00001
repeat {
  pp<-ro*exp(d$LogProb1)/(ro*exp(d$LogProb1)+(1-ro)*exp(d$LogProb0))
  ronew<-mean(pp)
# print(c(ro,ronew))
  if (abs(ro-ronew) <= tol){
    break
  }
  ro <- ronew
}
freqYpos<-sum(d$Obs>seuil)/length(d$Obs)
```

On trouve $\rho$= `r ro`, une valeur très proche de la proportion empirique `r freqYpos`.

Selon les préceptes de Krzysztofowicz, calculons les probabilités $[Z\vert y]$ lorsque la situation $Z$ est issue de ce modèle *boite noire* (sur l'échantillon de calage *d*).

```{r krz, results = 'hide', message = FALSE, warning = FALSE}
d$probazeq1 <- ro*exp(d$LogProb1)/(ro*exp(d$LogProb1)+(1-ro)*exp(d$LogProb0))
zy <- matrix(
  c(100*mean((d$Obs>seuil)*d$probazeq1),100*(mean((1-(d$Obs>seuil))*d$probazeq1)),
    100*mean((d$Obs>seuil)*(1-d$probazeq1)),100*(mean((1-(d$Obs>seuil))*(1-d$probazeq1)))),    byrow=T,nr=2,nc=2 )
row.names(zy)<-c("z=1","z=0")
colnames(zy)<-c("y=1","y=0")
# z en ligne y en colonne
probazeg1sachantyeg1=zy[1,1]/(zy[1,1]+zy[2,1])
probazeg1sachantyeg0=zy[1,2]/(zy[1,2]+zy[2,2])
probayeg1sachantzeg1=zy[1,1]/(zy[1,1]+zy[1,2])
probayeg1sachantzeg0=zy[1,2]/(zy[2,1]+zy[2,2])
```

```{r printzy, results='asis', message = FALSE, warning = FALSE}
knitr::kable(zy, caption = "Fréquences en pourcentage des générations du modèle préquentiel (considéré comme une boite noire selon Krystfowicz) sur l'échantillon de calage")
```

On peut dresser un tableau similaire pour la loi conditionnelle $[y\vert z]$:

```{r printzycond, results='asis', message = FALSE, warning = FALSE}
ycondz=zy/matrix(c((zy[1,1]+zy[1,2]),(zy[2,1]+zy[2,2]),
                  (zy[1,1]+zy[1,2]),(zy[2,1]+zy[2,2])),2,2)
knitr::kable(ycondz, caption = "Probabilités conditionnelles y sachant z d'après la machinerie recalant le modèle préquentiel considéré comme une boite noire")
```

Mais pour Krzysztofowicz, c'est essentiellement définir $[z\vert y]$ (cf Tableau 5) que permettent ces opérations puisque chacune des expériences enregistrées dans la base d'apprentissage correspond à un *état de la nature* $Y$ fixé à sa valeur $y$ et que nos élucabrations ont pour effet de lui associer un tirage de $Z$. 

```{r printyzcond, results='asis', message = FALSE, warning = FALSE}
zcondy=zy/matrix(c((zy[1,1]+zy[2,1]),(zy[2,1]+zy[1,1]),
                  (zy[2,2]+zy[1,2]),(zy[1,2]+zy[2,2])),2,2)
knitr::kable(zcondy, caption = "Probabilités conditionnelles z sachant y d'après la machinerie recalant le modèle préquentiel considéré comme une boite noire")
```


## Prédictive pour $y=1$ ou $y=0$ sachant l'ensemble
Il faut adopter *une* climatologie, c'est à dire la valeur de la probabilité marginale $[Y=1]$. Je vais prendre au plus simple $[Y=1]$=`r freqYpos` (la fréquence empirique de pluies non nulles pour la période sur la base de calage).  Ce choix arbitraire doit faire l'objet d'une discussion car on dispose d'une base historique qui permet une étude plus complète de la climatologie, du moins en principe (voir notre papier en projet sur les idées fausses en prévision d'ensemble).

On applique ensuite le *Bayesian processor of information* de Krzysztofowicz:
\[
\lbrack Y|X]=\int_{z}\left(  \frac{[Z|Y][Y]}{\int_{y}[Z|Y][Y]dY}\right)
[Z|X]dZ
\]
Le programme ci-après calcule chacun des termes de l'équation pour toute la base de données *dtout* considérée (calibrage+validation):
```{r calculepredictive, results = 'hide', message = FALSE, warning = FALSE}
dtout$margey<-freqYpos
dtout$probazeq1 <- ro*exp(dtout$LogProb1)/(ro*exp(dtout$LogProb1)+ (1-ro)*exp(dtout$LogProb0))
dtout$probayeq1sachantzeq1<-(probazeg1sachantyeg1*dtout$margey)/ (probazeg1sachantyeg1*dtout$margey + probazeg1sachantyeg0*(1-dtout$margey))
dtout$probayeq1sachantzeq0<-((1-probazeg1sachantyeg1)*dtout$margey)/ ((1-probazeg1sachantyeg1)*dtout$margey+ (1-probazeg1sachantyeg0)*(1-dtout$margey))
dtout$predictyeg1<-dtout$probayeq1sachantzeq1*dtout$probazeq1 + dtout$probayeq1sachantzeq0*(1-dtout$probazeq1)
## on sauve les resultats
 save(fit0, fit1,dtout, file = "ResultatsComplets.RData")
```


## Validation des situations sèche ou humide

On choisit pour période de validation la période posterieure au `r datecharniere` (la base de données de validation s'appelle *d* dans les programmes ci-après). La figure 3 montre le comportement du prédicteur bayésien ainsi construit.

```{r validation0, fig.cap="Prédictive bayésienne de Y=1 (En rouge: Yobs=1)"}
dtout %>% filter(Date>=datecharniere)->d
plot(d$predictyeg1,d$NX/K, col=1+(d$Obs>=seuil),pch=19, xlab="Proportion de membres nuls", ylab="Probabilité predictive  y=1")

```


Sur l'échantillon de validation, le score de Brier de la prédictive vaut `r mean((d$predictyeg1-(d$Obs>seuil))^2)` tandis que celui de la fréquence empirique des membres non nuls vaut `r mean((d$NX/K-(d$Obs>seuil))^2)` .

En appellant le package **verification**, on peut visualiser la performance de la prédictive ainsi calculée (Figure 4):
  
```{r validation1,fig.cap="Graphe de performance de la prédictive bayésienne", message = FALSE, warning = FALSE}
library(verification)
verif<-verify(obs = 1*(d$Obs>seuil), pred=d$predictyeg1, obs.type = "binary",pred.type='prob')
plot(verif)
```
 
 Elle a un peu meilleure allure que celle fondée sur la fréquence des membres non nuls donnée à la figure 5). 

 
```{r validation2,fig.cap="Graphe de performance de la prédictive fondée sur la fréquence des membres non nuls" , message = FALSE, warning = FALSE}
library(verification)
verifNX<-verify(obs = 1*(d$Obs>seuil), pred=d$NX/K, obs.type = "binary",pred.type='prob')
plot(verifNX)
```
 
En particulier la composante de fiabilité de son score vaut `r verif$bs.reliability` tandis qu'elle vaut `r verifNX$bs.reliability` pour l'estimateur naif. Mais on en paye le prix en terme de résolution :`r verif$bs.resol` au lieu de `r verifNX$bs.resol`

# Conclusions

Si j'essaye de résumer opérationnellement les concepts de Krzysztofowicz, je dirais: 

* construire une machinerie qui produit (stochastiquement) $\hat{y}$ (appelé $Z$ dans ce rapport) à partir de l'information $X$. Ce qui est surprenant, c'est que tous les moyens sont bons! D'une certain façon, on a cherché à utiliser $y$ au mieux pour entrainer un modèle statistique discriminant de mélange $[\hat{y}\vert X]$, mais aucune **rigueur** ne semble formellement nécessaire à ce stade.

* évaluer $[\hat{y}\vert y]$ sur un échantillon de calage

* choisir la marginale à respecter $[Y]$,

* produire la predictive \[[y\left| {X]} \right. = \int\limits_{\hat y}^{} {\left( {\frac{{[\hat y\left| {y][y]} \right.}}{{\left( {\int {[\hat y\left| {y][y]} \right.dy} } \right)}}} \right)}  \times [\hat y\left| {X]} \right.d\hat y\]

Je suis également embêté par la façon brutale d'évaluer le $\rho$ du mélange de la loi de $(NX,SX,SLX)$ sans considération pour l'incertitude.

J'ai essayé de respecter les principes du *tidyverse* mais je ne progresse que très lentement en programmation R et je bredouille beaucoup avec *ggplot2.*

Je suis très favorablement impressionné par l'efficacité de STAN.

Je me trouve finalement plutôt satisfait des résultats, malgré le nombre de données trop réduit qui ne plaît guère Jacques, mais ce n'est pas moi le pourvoyeur de données...

* on a pu procéder par calage et validation sur deux échantillons différents, comme il se doit.

* le score de Brier de la prédictive bayesienne semble meilleur que celui de la prévision empirique naive, même si je partage les critiques de Jacques à l'égard de ce score propre symétrique (cf projet de papier sur les idées fausses en previsions probabilistes d'ensemble).

* Cette amélioration provient d'un gain en fiabilité, même si on perd en terme de résolution. 

Reste maintenant à passer à la prévision de la quantité de pluie, ce qui fera l'objet d'une autre note. Le modèle des fuites échangeable est également à mettre en oeuvre.

# Discussion

J'ai recommencé l'étude 

* sur le printemps horizon = 3 jours. Le prédicteur naif reste alors encore derriere  avec un score de Brier de $0.165$ contre $0.136$ pour le bayésien, mais une composante de fiabilité plus mauvaise, de $0.0481$ contre $0.01$ pour le bayésien, et non compensée par une résolution de $0.113$ contre $0.124$ pour le bayésien.
* sur l'été horizon = 3 jours. Le prédicteur naif passe devant avec un score de Brier de $0.157$ contre $0.167$ pour le bayésien, mais une composante de fiabilité plus mauvaise, de $0.0371$ contre $0.0132$ pour le bayésien, mais compensée par une résolution de $0.129$ contre $0.0941$ pour le bayésien.
* sur l'été horizon = 4 jours, en posant saison $=printemps+90$. Le prédicteur naif passe alors devant avec un score de Brier de $0.166$ contre $0.167$ pour le bayésien, mais une composante de fiabilité plus mauvaise, de $0.0289$ contre $0.0156$ pour le bayésien, néanmoins compensée par une résolution de $0.112$ contre $0.972$ pour le bayésien.

* sur toute l'année , horizon = 4 jours en posant saison $=1:365$. Le prédicteur naif passe alors devant avec un score de Brier de $0.149$ contre $0.156$ pour le bayésien, mais une composante de fiabilité plus mauvaise, de $0.02$ contre $0.00598$ pour le bayésien, néanmoins compensée par une résolution de $0.121$ contre $0.1$ pour le bayésien.